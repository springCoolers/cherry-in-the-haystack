# generated by rye
# use `rye lock` or `rye sync` to update this lockfile
#
# last locked with the following flags:
#   pre: false
#   features: []
#   all-features: false
#   with-sources: false
#   generate-hashes: false
#   universal: false

-e file:.
ag2==0.9.7
    # via auto-news
aiofile==3.9.0
    # via miniopy-async
aiohappyeyeballs==2.6.1
    # via aiohttp
aiohttp==3.13.2
    # via langchain
    # via langchain-community
    # via litellm
    # via llama-index-core
    # via miniopy-async
aiosignal==1.4.0
    # via aiohttp
aiosqlite==0.22.0
    # via llama-index-core
annotated-types==0.7.0
    # via pydantic
anyio==4.12.0
    # via ag2
    # via asyncer
    # via httpx
    # via openai
    # via watchfiles
argon2-cffi==25.1.0
    # via minio
argon2-cffi-bindings==25.1.0
    # via argon2-cffi
arxiv==2.3.1
    # via auto-news
async-timeout==4.0.3
    # via aiohttp
    # via langchain
    # via redis
asyncer==0.0.8
    # via ag2
attrs==25.4.0
    # via aiohttp
    # via jsonschema
    # via referencing
backoff==2.2.1
    # via posthog
banks==2.2.0
    # via llama-index-core
bcrypt==5.0.0
    # via chromadb
beautifulsoup4==4.14.3
    # via bs4
    # via llama-index-readers-file
bs4==0.0.2
    # via auto-news
build==1.3.0
    # via chromadb
cachetools==6.2.3
    # via google-auth
caio==0.9.24
    # via aiofile
certifi==2025.11.12
    # via httpcore
    # via httpx
    # via kubernetes
    # via llama-cloud
    # via minio
    # via miniopy-async
    # via pinecone-client
    # via requests
cffi==2.0.0
    # via argon2-cffi-bindings
    # via soundfile
charset-normalizer==3.4.4
    # via requests
chromadb==1.3.7
    # via auto-news
click==8.1.8
    # via duckduckgo-search
    # via geomet
    # via litellm
    # via llama-cloud-services
    # via nltk
    # via typer
    # via uvicorn
colorama==0.4.6
    # via build
    # via click
    # via griffe
    # via tqdm
    # via uvicorn
coloredlogs==15.0.1
    # via onnxruntime
comtypes==1.4.13
    # via pyttsx3
cramjam==2.11.0
    # via python-snappy
dataclasses-json==0.6.7
    # via langchain-community
    # via llama-index-core
decorator==5.2.1
    # via retry
defusedxml==0.7.1
    # via llama-index-readers-file
    # via youtube-transcript-api
deprecated==1.2.18
    # via banks
    # via llama-index-core
    # via llama-index-indices-managed-llama-cloud
    # via llama-index-instrumentation
dirtyjson==1.0.8
    # via llama-index-core
diskcache==5.6.3
    # via ag2
distro==1.9.0
    # via openai
    # via posthog
docker==7.1.0
    # via ag2
    # via auto-news
duckduckgo-search==8.1.1
    # via auto-news
durationpy==0.10
    # via kubernetes
eval-type-backport==0.2.2
    # via banks
    # via llama-cloud-services
    # via llama-index-core
    # via llama-index-workflows
exceptiongroup==1.3.1
    # via anyio
fake-useragent==2.2.0
    # via auto-news
fastuuid==0.14.0
    # via litellm
feedparser==6.0.12
    # via arxiv
    # via auto-news
filelock==3.19.1
    # via huggingface-hub
    # via torch
    # via transformers
filetype==1.2.0
    # via langchain-google-genai
    # via llama-index-core
flatbuffers==25.9.23
    # via onnxruntime
frozenlist==1.8.0
    # via aiohttp
    # via aiosignal
fsspec==2025.10.0
    # via huggingface-hub
    # via llama-index-core
    # via torch
geomet==1.1.0
    # via scylla-driver
google-ai-generativelanguage==0.6.15
    # via google-generativeai
google-api-core==2.28.1
    # via google-ai-generativelanguage
    # via google-api-python-client
    # via google-generativeai
google-api-python-client==2.187.0
    # via google-generativeai
google-auth==2.43.0
    # via google-ai-generativelanguage
    # via google-api-core
    # via google-api-python-client
    # via google-auth-httplib2
    # via google-generativeai
    # via kubernetes
google-auth-httplib2==0.2.1
    # via google-api-python-client
google-generativeai==0.8.5
    # via auto-news
    # via langchain-google-genai
googleapis-common-protos==1.72.0
    # via google-api-core
    # via grpcio-status
    # via opentelemetry-exporter-otlp-proto-grpc
greenlet==3.2.4
    # via sqlalchemy
griffe==1.14.0
    # via banks
grpcio==1.67.1
    # via chromadb
    # via google-api-core
    # via grpcio-status
    # via litellm
    # via opentelemetry-exporter-otlp-proto-grpc
    # via pymilvus
grpcio-status==1.67.1
    # via google-api-core
h11==0.16.0
    # via httpcore
    # via uvicorn
httpcore==1.0.9
    # via auto-news
    # via httpx
httplib2==0.31.0
    # via google-api-python-client
    # via google-auth-httplib2
httptools==0.7.1
    # via uvicorn
httpx==0.28.1
    # via ag2
    # via auto-news
    # via chromadb
    # via langsmith
    # via litellm
    # via llama-cloud
    # via llama-index-core
    # via notion-client
    # via openai
huggingface-hub==0.36.0
    # via tokenizers
    # via transformers
humanfriendly==10.0
    # via coloredlogs
idna==3.11
    # via anyio
    # via httpx
    # via requests
    # via yarl
importlib-metadata==8.7.0
    # via build
    # via litellm
    # via opentelemetry-api
importlib-resources==6.5.2
    # via chromadb
    # via fake-useragent
jinja2==3.1.6
    # via banks
    # via litellm
    # via torch
jiter==0.12.0
    # via openai
joblib==1.5.3
    # via nltk
    # via scikit-learn
jsonpatch==1.33
    # via langchain-core
jsonpointer==3.0.0
    # via jsonpatch
jsonschema==4.25.1
    # via chromadb
    # via litellm
jsonschema-specifications==2025.9.1
    # via jsonschema
kubernetes==33.1.0
    # via chromadb
langchain==0.3.1
    # via auto-news
    # via langchain-community
langchain-community==0.3.1
    # via auto-news
langchain-core==0.3.63
    # via langchain
    # via langchain-community
    # via langchain-google-genai
    # via langchain-text-splitters
langchain-google-genai==2.0.10
    # via auto-news
langchain-text-splitters==0.3.8
    # via langchain
langsmith==0.1.147
    # via langchain
    # via langchain-community
    # via langchain-core
litellm==1.80.10
    # via auto-news
llama-cloud==0.1.35
    # via llama-cloud-services
    # via llama-index-indices-managed-llama-cloud
llama-cloud-services==0.6.54
    # via llama-parse
llama-index==0.14.10
    # via auto-news
llama-index-core==0.14.10
    # via llama-cloud-services
    # via llama-index
    # via llama-index-embeddings-openai
    # via llama-index-indices-managed-llama-cloud
    # via llama-index-llms-openai
    # via llama-index-readers-file
    # via llama-index-readers-llama-parse
llama-index-embeddings-openai==0.5.1
    # via llama-index
llama-index-indices-managed-llama-cloud==0.9.4
    # via llama-index
llama-index-instrumentation==0.4.2
    # via llama-index-workflows
llama-index-llms-openai==0.6.11
    # via llama-index
llama-index-readers-file==0.5.5
    # via llama-index
llama-index-readers-llama-parse==0.5.1
    # via llama-index
llama-index-workflows==2.11.5
    # via llama-index-core
llama-parse==0.6.54
    # via llama-index-readers-llama-parse
llvmlite==0.43.0
    # via numba
lxml==6.0.2
    # via duckduckgo-search
lz4==4.4.5
    # via auto-news
markdown-it-py==3.0.0
    # via rich
markupsafe==3.0.3
    # via jinja2
marshmallow==3.26.1
    # via dataclasses-json
mdurl==0.1.2
    # via markdown-it-py
minio==7.2.20
    # via auto-news
miniopy-async==1.21.2
    # via auto-news
mmh3==5.2.0
    # via chromadb
more-itertools==10.8.0
    # via openai-whisper
mpmath==1.3.0
    # via sympy
multidict==6.7.0
    # via aiohttp
    # via yarl
mypy-extensions==1.1.0
    # via typing-inspect
mysql-connector-python==9.4.0
    # via auto-news
nest-asyncio==1.6.0
    # via llama-index-core
networkx==3.2.1
    # via llama-index-core
    # via torch
nltk==3.9.2
    # via llama-index
    # via llama-index-core
notion-client==2.7.0
    # via auto-news
numba==0.60.0
    # via openai-whisper
numpy==1.26.4
    # via chromadb
    # via langchain
    # via langchain-community
    # via llama-index-core
    # via numba
    # via onnxruntime
    # via openai-whisper
    # via pandas
    # via scikit-learn
    # via scipy
    # via soundfile
    # via transformers
oauthlib==3.3.1
    # via kubernetes
    # via requests-oauthlib
    # via tweepy
onnxruntime==1.19.2
    # via chromadb
openai==2.11.0
    # via auto-news
    # via litellm
    # via llama-index-embeddings-openai
    # via llama-index-llms-openai
openai-whisper==20250625
    # via auto-news
opentelemetry-api==1.39.1
    # via chromadb
    # via opentelemetry-exporter-otlp-proto-grpc
    # via opentelemetry-sdk
    # via opentelemetry-semantic-conventions
opentelemetry-exporter-otlp-proto-common==1.39.1
    # via opentelemetry-exporter-otlp-proto-grpc
opentelemetry-exporter-otlp-proto-grpc==1.39.1
    # via chromadb
opentelemetry-proto==1.39.1
    # via opentelemetry-exporter-otlp-proto-common
    # via opentelemetry-exporter-otlp-proto-grpc
opentelemetry-sdk==1.39.1
    # via chromadb
    # via opentelemetry-exporter-otlp-proto-grpc
opentelemetry-semantic-conventions==0.60b1
    # via opentelemetry-sdk
orjson==3.11.5
    # via chromadb
    # via langsmith
    # via pymilvus
overrides==7.7.0
    # via chromadb
packaging==24.2
    # via ag2
    # via build
    # via huggingface-hub
    # via langchain-core
    # via marshmallow
    # via onnxruntime
    # via transformers
pandas==2.2.3
    # via llama-index-readers-file
    # via pymilvus
pillow==11.3.0
    # via auto-news
    # via llama-index-core
pinecone-client==6.0.0
    # via auto-news
pinecone-plugin-interface==0.0.7
    # via pinecone-client
platformdirs==4.4.0
    # via banks
    # via llama-cloud-services
    # via llama-index-core
posthog==5.4.0
    # via chromadb
primp==0.15.0
    # via duckduckgo-search
propcache==0.4.1
    # via aiohttp
    # via yarl
proto-plus==1.26.1
    # via google-ai-generativelanguage
    # via google-api-core
protobuf==5.29.5
    # via google-ai-generativelanguage
    # via google-api-core
    # via google-generativeai
    # via googleapis-common-protos
    # via grpcio-status
    # via onnxruntime
    # via opentelemetry-proto
    # via proto-plus
    # via pymilvus
py==1.11.0
    # via retry
pyasn1==0.6.1
    # via pyasn1-modules
    # via rsa
pyasn1-modules==0.4.2
    # via google-auth
pybase64==1.4.3
    # via chromadb
pycparser==2.23
    # via cffi
pycryptodome==3.23.0
    # via minio
pydantic==2.12.5
    # via ag2
    # via banks
    # via chromadb
    # via google-generativeai
    # via langchain
    # via langchain-core
    # via langchain-google-genai
    # via langsmith
    # via litellm
    # via llama-cloud
    # via llama-cloud-services
    # via llama-index-core
    # via llama-index-instrumentation
    # via llama-index-workflows
    # via openai
    # via pydantic-settings
pydantic-core==2.41.5
    # via pydantic
pydantic-settings==2.11.0
    # via langchain-community
pygments==2.19.2
    # via rich
pymilvus==2.6.5
    # via auto-news
pymupdf==1.26.5
    # via auto-news
pyparsing==3.2.5
    # via httplib2
pypdf==6.4.2
    # via llama-index-readers-file
pypika==0.48.9
    # via chromadb
pypiwin32==223
    # via pyttsx3
pyproject-hooks==1.2.0
    # via build
pyreadline3==3.5.4
    # via humanfriendly
python-dateutil==2.9.0.post0
    # via kubernetes
    # via pandas
    # via pinecone-client
    # via posthog
python-dotenv==1.2.1
    # via ag2
    # via auto-news
    # via litellm
    # via llama-cloud-services
    # via pydantic-settings
    # via pymilvus
    # via uvicorn
python-snappy==0.7.3
    # via auto-news
pyttsx3==2.99
    # via auto-news
pytube==15.0.0
    # via auto-news
pytz==2025.2
    # via auto-news
    # via pandas
pywin32==311
    # via docker
    # via pypiwin32
    # via pyttsx3
pyyaml==6.0.3
    # via chromadb
    # via huggingface-hub
    # via kubernetes
    # via langchain
    # via langchain-community
    # via langchain-core
    # via llama-index-core
    # via scylla-driver
    # via transformers
    # via uvicorn
redis==7.0.1
    # via auto-news
referencing==0.36.2
    # via jsonschema
    # via jsonschema-specifications
regex==2025.11.3
    # via nltk
    # via tiktoken
    # via transformers
requests==2.32.5
    # via arxiv
    # via auto-news
    # via docker
    # via google-api-core
    # via huggingface-hub
    # via kubernetes
    # via langchain
    # via langchain-community
    # via langsmith
    # via llama-index-core
    # via posthog
    # via requests-oauthlib
    # via requests-toolbelt
    # via tiktoken
    # via transformers
    # via tweepy
    # via youtube-transcript-api
requests-oauthlib==2.0.0
    # via kubernetes
    # via tweepy
requests-toolbelt==1.0.0
    # via langsmith
retry==0.9.2
    # via auto-news
rich==14.2.0
    # via chromadb
    # via typer
rpds-py==0.27.1
    # via jsonschema
    # via referencing
rsa==4.9.1
    # via google-auth
safetensors==0.7.0
    # via transformers
scales==1.0.9
    # via auto-news
scikit-learn==1.6.1
    # via auto-news
scipy==1.13.1
    # via scikit-learn
scylla-driver==3.29.7
    # via auto-news
setuptools==80.9.0
    # via llama-index-core
    # via pymilvus
sgmllib3k==1.0.0
    # via feedparser
shellingham==1.5.4
    # via typer
six==1.17.0
    # via kubernetes
    # via posthog
    # via python-dateutil
    # via scales
sniffio==1.3.1
    # via openai
soundfile==0.13.1
    # via auto-news
soupsieve==2.8
    # via beautifulsoup4
speechrecognition==3.14.4
    # via auto-news
sqlalchemy==2.0.45
    # via langchain
    # via langchain-community
    # via llama-index-core
striprtf==0.0.26
    # via llama-index-readers-file
sympy==1.14.0
    # via onnxruntime
    # via torch
tenacity==8.5.0
    # via chromadb
    # via langchain
    # via langchain-community
    # via langchain-core
    # via llama-cloud-services
    # via llama-index-core
termcolor==3.1.0
    # via ag2
threadpoolctl==3.6.0
    # via scikit-learn
tiktoken==0.12.0
    # via ag2
    # via auto-news
    # via litellm
    # via llama-index-core
    # via openai-whisper
tokenizers==0.22.1
    # via chromadb
    # via litellm
    # via transformers
tomli==2.3.0
    # via build
torch==2.8.0
    # via openai-whisper
tqdm==4.67.1
    # via chromadb
    # via google-generativeai
    # via huggingface-hub
    # via llama-index-core
    # via nltk
    # via openai
    # via openai-whisper
    # via transformers
transformers==4.57.3
    # via auto-news
tweepy==4.16.0
    # via auto-news
typer==0.20.0
    # via chromadb
typing-extensions==4.15.0
    # via aiosignal
    # via anyio
    # via asyncer
    # via beautifulsoup4
    # via chromadb
    # via exceptiongroup
    # via google-generativeai
    # via huggingface-hub
    # via langchain-core
    # via llama-index-core
    # via llama-index-workflows
    # via minio
    # via miniopy-async
    # via multidict
    # via openai
    # via opentelemetry-api
    # via opentelemetry-exporter-otlp-proto-grpc
    # via opentelemetry-sdk
    # via opentelemetry-semantic-conventions
    # via pinecone-client
    # via pydantic
    # via pydantic-core
    # via pypdf
    # via referencing
    # via speechrecognition
    # via sqlalchemy
    # via torch
    # via typer
    # via typing-inspect
    # via typing-inspection
    # via uvicorn
typing-inspect==0.9.0
    # via dataclasses-json
    # via llama-index-core
typing-inspection==0.4.2
    # via pydantic
    # via pydantic-settings
tzdata==2025.3
    # via pandas
uritemplate==4.2.0
    # via google-api-python-client
urllib3==2.6.2
    # via docker
    # via kubernetes
    # via minio
    # via miniopy-async
    # via pinecone-client
    # via requests
uvicorn==0.38.0
    # via chromadb
validators==0.35.0
    # via auto-news
watchfiles==1.1.1
    # via uvicorn
websocket-client==1.9.0
    # via kubernetes
websockets==15.0.1
    # via uvicorn
wrapt==1.17.3
    # via deprecated
    # via llama-index-core
yarl==1.22.0
    # via aiohttp
youtube-transcript-api==1.2.3
    # via auto-news
yt-dlp==2025.10.14
    # via auto-news
zipp==3.23.0
    # via importlib-metadata
    # via importlib-resources
