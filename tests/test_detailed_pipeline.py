#!/usr/bin/env python3
"""
ìƒì„¸ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ - TOC ê¸°ë°˜ ì±•í„°/ì„¹ì…˜/ë¬¸ë‹¨/ì•„ì´ë””ì–´ ì „ì²´ í™•ì¸

PDF â†’ TOC ê¸°ë°˜ ì±•í„°/ì„¹ì…˜ ê°ì§€ â†’ ë¬¸ë‹¨ ë¶„í•  â†’ ì•„ì´ë””ì–´ ì¶”ì¶œ
ê²°ê³¼ë¥¼ JSON íŒŒì¼ê³¼ ì½˜ì†”ì— ì¶œë ¥.
"""

import sys
import json
from pathlib import Path
from datetime import datetime

sys.path.insert(0, str(Path(__file__).parent.parent))

from rich.console import Console
from rich.panel import Panel
from rich.tree import Tree
from rich.table import Table
from rich.progress import Progress, SpinnerColumn, TextColumn

from src.workflow.state import create_initial_state
from src.workflow.nodes import extract_text, chunk_paragraphs
from src.workflow.nodes.extract_ideas import extract_idea
from src.utils.pdf.hierarchy_detector import (
    detect_chapters_from_toc,
    get_leaf_sections,
)

console = Console()

# Front matter íŒ¨í„´ (ê±´ë„ˆë›¸ ì±•í„°ë“¤)
FRONT_MATTER_PATTERNS = [
    "Cover",
    "Copyright",
    "Table of Contents",
    "Preface",
    "Acknowledgments",
    "Foreword",
    "Introduction",  # ì£¼ì˜: ì¼ë¶€ ì±…ì—ì„œëŠ” ì‹¤ì œ ì±•í„°ì¼ ìˆ˜ ìˆìŒ
    "About the Author",
    "About the",
    "Dedication",
    "Contents",
]


def is_front_matter(title: str) -> bool:
    """Front matter ì±•í„°ì¸ì§€ í™•ì¸."""
    title_lower = title.lower().strip()
    for pattern in FRONT_MATTER_PATTERNS:
        if title_lower.startswith(pattern.lower()):
            return True
    return False


def run_detailed_test(
    pdf_path: str,
    max_chapters: int = 3,
    max_sections_per_chapter: int = 5,
    max_paragraphs_per_section: int = 5,
    output_json: bool = True,
    start_chapter: int = 1,
    skip_front_matter: bool = False,
):
    """
    TOC ê¸°ë°˜ ìƒì„¸ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰.

    Args:
        pdf_path: PDF íŒŒì¼ ê²½ë¡œ
        max_chapters: í…ŒìŠ¤íŠ¸í•  ìµœëŒ€ ì±•í„° ìˆ˜
        max_sections_per_chapter: ì±•í„°ë‹¹ í…ŒìŠ¤íŠ¸í•  ìµœëŒ€ ì„¹ì…˜ ìˆ˜
        max_paragraphs_per_section: ì„¹ì…˜ë‹¹ ì•„ì´ë””ì–´ ì¶”ì¶œí•  ìµœëŒ€ ë¬¸ë‹¨ ìˆ˜
        output_json: JSON íŒŒì¼ë¡œ ê²°ê³¼ ì €ì¥ ì—¬ë¶€
        start_chapter: ì‹œì‘ ì±•í„° ë²ˆí˜¸ (1-indexed, í•„í„°ë§ í›„ ê¸°ì¤€)
        skip_front_matter: Front matter (Preface ë“±) ê±´ë„ˆë›°ê¸°
    """
    results = {
        "pdf_path": pdf_path,
        "timestamp": datetime.now().isoformat(),
        "pipeline_type": "toc",
        "options": {
            "start_chapter": start_chapter,
            "skip_front_matter": skip_front_matter,
            "max_chapters": max_chapters,
            "max_sections_per_chapter": max_sections_per_chapter,
            "max_paragraphs_per_section": max_paragraphs_per_section,
        },
        "summary": {},
        "chapters": []
    }

    console.print(Panel.fit(
        f"[bold blue]TOC ê¸°ë°˜ ìƒì„¸ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸[/bold blue]\n"
        f"PDF: {pdf_path}\n"
        f"ìµœëŒ€ ì±•í„°: {max_chapters}ê°œ | ì„¹ì…˜: {max_sections_per_chapter}ê°œ | ë¬¸ë‹¨: {max_paragraphs_per_section}ê°œ\n"
        f"ì‹œì‘ ì±•í„°: {start_chapter} | Front matter ê±´ë„ˆë›°ê¸°: {'ì˜ˆ' if skip_front_matter else 'ì•„ë‹ˆì˜¤'}\n"
        f"ê°ì§€ ë°©ë²•: [yellow]TOC (PDF ëª©ì°¨ ê¸°ë°˜)[/yellow]"
    ))

    # ============================================================
    # 1. PDF â†’ Plain Text + TOC ì¶”ì¶œ
    # ============================================================
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        console=console,
    ) as progress:
        task = progress.add_task("PDF â†’ Plain Text + TOC ì¶”ì¶œ ì¤‘...", total=None)
        state = create_initial_state(pdf_path=pdf_path)
        state = extract_text(state)

        if state.get("error"):
            console.print(f"[red]âŒ ì—ëŸ¬: {state['error']}[/red]")
            return

        plain_text = state.get("plain_text", "")
        toc = state.get("toc", [])
        has_toc = state.get("has_toc", False)
        page_positions = state.get("page_positions", [])

        console.print(f"\n[green]âœ… Plain Text + TOC ì¶”ì¶œ ì™„ë£Œ[/green]")
        console.print(f"   í…ìŠ¤íŠ¸ ê¸¸ì´: {len(plain_text):,}ì")
        console.print(f"   TOC í•­ëª©: {len(toc)}ê°œ {'âœ…' if has_toc else 'âŒ (TOC ì—†ìŒ)'}")

        if not has_toc:
            console.print("[red]âŒ PDFì— TOCê°€ ì—†ìŠµë‹ˆë‹¤.[/red]")
            return

        # Step 2: TOC ê¸°ë°˜ ì±•í„°/ì„¹ì…˜ ê°ì§€
        progress.update(task, description="TOC ê¸°ë°˜ ì±•í„°/ì„¹ì…˜ ê°ì§€ ì¤‘...")
        chapters = detect_chapters_from_toc(
            pdf_path=pdf_path,
            plain_text=plain_text,
            page_positions=page_positions,
        )
        console.print(f"   ê°ì§€ëœ ì±•í„°: {len(chapters)}ê°œ")

    # ê¸°ë³¸ ì •ë³´
    results["summary"]["text_length"] = len(plain_text)
    results["summary"]["total_chapters"] = len(chapters)

    # ì „ì²´ ì„¹ì…˜ ìˆ˜ ê³„ì‚°
    def count_sections(sections):
        count = len(sections)
        for sec in sections:
            count += count_sections(sec.children)
        return count

    total_sections = sum(count_sections(ch.sections) for ch in chapters)
    results["summary"]["total_sections"] = total_sections

    console.print(f"   ê°ì§€ëœ ì„¹ì…˜: {total_sections}ê°œ")

    # ============================================================
    # 2. ì±•í„° í•„í„°ë§
    # ============================================================
    filtered_chapters = chapters

    if skip_front_matter:
        original_count = len(filtered_chapters)
        filtered_chapters = [ch for ch in filtered_chapters if not is_front_matter(ch.title)]
        skipped_count = original_count - len(filtered_chapters)
        if skipped_count > 0:
            console.print(f"\n[yellow]ğŸ“Œ Front matter {skipped_count}ê°œ ì±•í„° ê±´ë„ˆëœ€[/yellow]")

    # ì‹œì‘ ì±•í„° ì ìš© (1-indexed)
    if start_chapter > 1:
        filtered_chapters = filtered_chapters[start_chapter - 1:]
        console.print(f"[yellow]ğŸ“Œ ì±•í„° {start_chapter}ë¶€í„° ì‹œì‘[/yellow]")

    if not filtered_chapters:
        console.print("[red]âŒ ì²˜ë¦¬í•  ì±•í„°ê°€ ì—†ìŠµë‹ˆë‹¤.[/red]")
        return

    results["summary"]["filtered_chapters"] = len(filtered_chapters)

    # ============================================================
    # 3. ë¬¸ì„œ êµ¬ì¡° íŠ¸ë¦¬ ì¶œë ¥
    # ============================================================
    console.print(f"\n[yellow]ğŸ“š ë¬¸ì„œ êµ¬ì¡° íŠ¸ë¦¬ (TOC ê¸°ë°˜)[/yellow]")
    doc_tree = Tree("[bold]ğŸ“– ë¬¸ì„œ êµ¬ì¡°[/bold]")

    def add_sections_to_tree(parent_branch, sections, max_show=5):
        for idx, section in enumerate(sections[:max_show]):
            child_count = len(section.children)
            sec_branch = parent_branch.add(
                f"[green]L{section.level}. {section.title[:40]}[/green] "
                f"({len(section.content):,}ì, {child_count} í•˜ìœ„)"
            )
            if section.children:
                add_sections_to_tree(sec_branch, section.children, max_show=3)
        if len(sections) > max_show:
            parent_branch.add(f"[dim]... (+{len(sections) - max_show}ê°œ)[/dim]")

    for ch_idx, chapter in enumerate(filtered_chapters[:10]):
        section_count = count_sections(chapter.sections)
        ch_branch = doc_tree.add(
            f"[bold cyan]Ch{chapter.chapter_number}. {chapter.title[:50]}[/bold cyan] "
            f"({len(chapter.content):,}ì, {section_count} ì„¹ì…˜)"
        )
        add_sections_to_tree(ch_branch, chapter.sections, max_show=5)

    if len(filtered_chapters) > 10:
        doc_tree.add(f"[dim]... (+{len(filtered_chapters) - 10}ê°œ ì±•í„°)[/dim]")

    console.print(doc_tree)

    # ============================================================
    # 4. ì±•í„°ë³„ ìƒì„¸ ì²˜ë¦¬
    # ============================================================
    total_paragraphs = 0
    total_ideas = 0

    for ch_idx, chapter in enumerate(filtered_chapters[:max_chapters]):
        console.print(f"\n{'='*70}")
        console.print(f"[bold yellow]ğŸ“– ì±•í„° {chapter.chapter_number}: {chapter.title}[/bold yellow]")
        console.print(f"   ë³¸ë¬¸: {len(chapter.content):,}ì | ì„¹ì…˜: {len(chapter.sections)}ê°œ")
        console.print(f"   ê°ì§€ ë°©ë²•: {chapter.detection_method}")
        console.print(f"{'='*70}")

        chapter_result = {
            "chapter_number": chapter.chapter_number,
            "title": chapter.title,
            "detection_method": chapter.detection_method,
            "text_length": len(chapter.content),
            "section_count": len(chapter.sections),
            "sections": []
        }

        # ë§ë‹¨ ì„¹ì…˜ ì¶”ì¶œ
        leaf_sections = get_leaf_sections(chapter)
        tested_sections = 0

        for section, hierarchy_path in leaf_sections[:max_sections_per_chapter]:
            console.print(f"\n   [cyan]{'â”€'*50}[/cyan]")
            console.print(f"   [bold cyan]ğŸ“‘ {section.title}[/bold cyan]")
            console.print(f"   ê³„ì¸µ: {hierarchy_path}")
            console.print(f"   ë ˆë²¨: {section.level} | ë³¸ë¬¸: {len(section.content):,}ì")

            if len(section.content.strip()) < 100:
                console.print("   [dim]âš ï¸ ë³¸ë¬¸ì´ ë„ˆë¬´ ì§§ì•„ ê±´ë„ˆëœë‹ˆë‹¤.[/dim]")
                continue

            tested_sections += 1

            section_result = {
                "title": section.title,
                "level": section.level,
                "hierarchy_path": hierarchy_path,
                "text_length": len(section.content),
                "paragraphs": []
            }

            # ì„¹ì…˜ ìƒíƒœ ìƒì„±
            section_state = {
                **state,
                "current_chapter": chapter,
                "current_section": section,
                "current_section_text": section.content,
                "current_chapter_id": ch_idx + 1,
                "hierarchy_path": hierarchy_path,
                "book_id": None,
            }

            # ì²­í‚¹ ìˆ˜í–‰ (LLM ê¸°ë°˜)
            try:
                section_state = chunk_paragraphs(section_state)
                chunks = section_state.get("chunks", [])
                console.print(f"   âœ… {len(chunks)}ê°œ ë¬¸ë‹¨ ë¶„í•  ì™„ë£Œ")
            except Exception as e:
                console.print(f"   [red]âŒ ì²­í‚¹ ì‹¤íŒ¨: {e}[/red]")
                chunks = []

            total_paragraphs += len(chunks)
            section_result["paragraph_count"] = len(chunks)

            # ë¬¸ë‹¨ë³„ ì•„ì´ë””ì–´ ì¶”ì¶œ
            for para_idx, chunk in enumerate(chunks[:max_paragraphs_per_section]):
                console.print(f"\n      [dim]â”€â”€ ë¬¸ë‹¨ {para_idx + 1}/{len(chunks)} ({len(chunk.text)}ì) â”€â”€[/dim]")

                # í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°
                preview = chunk.text[:200].replace('\n', ' ')
                if len(chunk.text) > 200:
                    preview += "..."
                console.print(f"      [dim]{preview}[/dim]")

                # ê³„ì¸µ ì •ë³´ ì¶œë ¥
                console.print(f"      [cyan]ê³„ì¸µ: {chunk.hierarchy_path}[/cyan]")

                paragraph_result = {
                    "index": para_idx + 1,
                    "text": chunk.text,
                    "text_length": len(chunk.text),
                    "hierarchy_path": chunk.hierarchy_path,
                    "detection_method": chunk.detection_method,
                }

                # LLMìœ¼ë¡œ ê°œë… ì¶”ì¶œ
                chunk_state = {**section_state, "current_chunk": chunk}
                try:
                    result_state = extract_idea(chunk_state)
                    extracted = result_state.get("extracted_idea")

                    if extracted and extracted.concept:
                        console.print(f"      [green]âœ… í•µì‹¬ ê°œë…: {extracted.concept}[/green]")
                        paragraph_result["concept"] = extracted.concept
                        total_ideas += 1
                    else:
                        console.print(f"      [yellow]âš ï¸ ì¶”ì¶œëœ ê°œë… ì—†ìŒ[/yellow]")
                        paragraph_result["concept"] = None

                except Exception as e:
                    console.print(f"      [red]âŒ ì¶”ì¶œ ì‹¤íŒ¨: {e}[/red]")
                    paragraph_result["concept"] = None
                    paragraph_result["error"] = str(e)

                section_result["paragraphs"].append(paragraph_result)

            # ë‚˜ë¨¸ì§€ ë¬¸ë‹¨ (ì•„ì´ë””ì–´ ì¶”ì¶œ ì—†ì´)
            if len(chunks) > max_paragraphs_per_section:
                remaining = len(chunks) - max_paragraphs_per_section
                console.print(f"\n      [dim]... +{remaining}ê°œ ë¬¸ë‹¨ (ì•„ì´ë””ì–´ ì¶”ì¶œ ìƒëµ)[/dim]")

            chapter_result["sections"].append(section_result)

        # ë‚˜ë¨¸ì§€ ì„¹ì…˜
        if len(leaf_sections) > max_sections_per_chapter:
            remaining = len(leaf_sections) - max_sections_per_chapter
            console.print(f"\n   [dim]... +{remaining}ê°œ ì„¹ì…˜ (ì²˜ë¦¬ ìƒëµ)[/dim]")

        results["chapters"].append(chapter_result)

    # ============================================================
    # 5. ìµœì¢… ìš”ì•½
    # ============================================================
    results["summary"]["tested_chapters"] = min(max_chapters, len(filtered_chapters))
    results["summary"]["total_paragraphs"] = total_paragraphs
    results["summary"]["total_ideas_extracted"] = total_ideas

    console.print(f"\n{'='*70}")
    console.print("[bold green]ğŸ“Š ìµœì¢… ìš”ì•½[/bold green]")
    console.print(f"{'='*70}")

    summary_table = Table(show_header=False, box=None)
    summary_table.add_column("í•­ëª©", style="cyan")
    summary_table.add_column("ê°’", style="white")

    summary_table.add_row("í…ìŠ¤íŠ¸ ê¸¸ì´", f"{len(plain_text):,}ì")
    summary_table.add_row("ê°ì§€ëœ ì „ì²´ ì±•í„°", str(len(chapters)))
    summary_table.add_row("í•„í„°ë§ í›„ ì±•í„°", str(len(filtered_chapters)))
    summary_table.add_row("ê°ì§€ëœ ì „ì²´ ì„¹ì…˜", str(total_sections))
    summary_table.add_row("í…ŒìŠ¤íŠ¸í•œ ì±•í„°", str(min(max_chapters, len(filtered_chapters))))
    summary_table.add_row("ì²˜ë¦¬ëœ ë¬¸ë‹¨", str(total_paragraphs))
    summary_table.add_row("ì¶”ì¶œëœ ì•„ì´ë””ì–´", str(total_ideas))
    summary_table.add_row("ê°ì§€ ë°©ë²•", "TOC (PDF ëª©ì°¨)")

    console.print(summary_table)

    # JSON ì €ì¥
    if output_json:
        output_path = Path("pipeline_test_results.json")
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        console.print(f"\n[green]ğŸ“ ê²°ê³¼ ì €ì¥: {output_path}[/green]")

    return results


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="TOC ê¸°ë°˜ ìƒì„¸ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸")
    parser.add_argument("pdf_path", nargs="?", default="AI Engineering.pdf")
    parser.add_argument("--chapters", "-c", type=int, default=2, help="í…ŒìŠ¤íŠ¸í•  ì±•í„° ìˆ˜")
    parser.add_argument("--sections", "-s", type=int, default=3, help="ì±•í„°ë‹¹ ì„¹ì…˜ ìˆ˜")
    parser.add_argument("--paragraphs", "-p", type=int, default=3, help="ì„¹ì…˜ë‹¹ ì•„ì´ë””ì–´ ì¶”ì¶œí•  ë¬¸ë‹¨ ìˆ˜")
    parser.add_argument("--start-chapter", type=int, default=1, help="ì‹œì‘ ì±•í„° ë²ˆí˜¸ (1-indexed, í•„í„°ë§ í›„ ê¸°ì¤€)")
    parser.add_argument("--skip-front-matter", action="store_true", help="Front matter (Preface ë“±) ê±´ë„ˆë›°ê¸°")
    parser.add_argument("--no-json", action="store_true", help="JSON ì €ì¥ ì•ˆí•¨")

    args = parser.parse_args()

    pdf_path = Path(args.pdf_path)
    if not pdf_path.exists():
        pdf_path = Path(__file__).parent.parent / args.pdf_path

    if not pdf_path.exists():
        console.print(f"[red]âŒ íŒŒì¼ ì—†ìŒ: {args.pdf_path}[/red]")
        sys.exit(1)

    run_detailed_test(
        str(pdf_path),
        max_chapters=args.chapters,
        max_sections_per_chapter=args.sections,
        max_paragraphs_per_section=args.paragraphs,
        output_json=not args.no_json,
        start_chapter=args.start_chapter,
        skip_front_matter=args.skip_front_matter,
    )
